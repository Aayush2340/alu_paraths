{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T05:19:14.195819Z",
     "start_time": "2024-08-27T05:19:14.191322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-colorblind\")"
   ],
   "id": "26c09a474e48c85b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T06:28:30.274649Z",
     "start_time": "2024-08-27T06:28:27.752196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install jupyter-black\n",
    "\n",
    "\n",
    "%load_ext jupyter_black\n",
    "\n"
   ],
   "id": "9fa2333618a23fb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-black in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: black>=21 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-black) (24.8.0)\n",
      "Requirement already satisfied: ipython>=7 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-black) (8.25.0)\n",
      "Requirement already satisfied: tokenize-rt>=4 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-black) (6.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from black>=21->jupyter-black) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from black>=21->jupyter-black) (1.0.0)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from black>=21->jupyter-black) (24.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from black>=21->jupyter-black) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from black>=21->jupyter-black) (4.2.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7->jupyter-black) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7->jupyter-black) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7->jupyter-black) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7->jupyter-black) (3.0.45)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7->jupyter-black) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7->jupyter-black) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7->jupyter-black) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7->jupyter-black) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=7->jupyter-black) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7->jupyter-black) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7->jupyter-black) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7->jupyter-black) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7->jupyter-black) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=7->jupyter-black) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!ls ../input/asl-signs/ -GFlash --color",
   "id": "68309a1547cf2ba2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BASE_DIR = '../input/asl-signs/'\n",
    "train = pd.read_csv(f'{BASE_DIR}/train.csv')"
   ],
   "id": "4a082b10ad21258c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.head()",
   "id": "ca2ba244262a277",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "train[\"sign\"].value_counts().head(50).sort_values(ascending=True).plot(\n",
    "    kind=\"barh\", ax=ax, title=\"Top 50 Signs in Training Dataset\"\n",
    ")\n",
    "ax.set_xlabel(\"Number of Training Examples\")\n",
    "plt.show()"
   ],
   "id": "8cdf12ed0eeb4b25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T05:19:16.861972Z",
     "start_time": "2024-08-27T05:19:16.860971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "train[\"sign\"].value_counts().tail(50).sort_values(ascending=True).plot(\n",
    "    kind=\"barh\", ax=ax, title=\"Bottom 50 Signs in Training Dataset\"\n",
    ")\n",
    "ax.set_xlabel(\"Number of Training Examples\")\n",
    "plt.show()"
   ],
   "id": "c0869a2f652a4205",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "example_fn = train.query('sign == \"listen\"')[\"path\"].values[0]\n",
    "\n",
    "example_landmark = pd.read_parquet(f\"{BASE_DIR}/{example_fn}\")\n",
    "example_landmark.head()"
   ],
   "id": "411b658dd3bf9a9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unique_frames = example_landmark[\"frame\"].nunique()\n",
    "unique_types = example_landmark[\"type\"].nunique()\n",
    "types_in_video = example_landmark[\"type\"].unique()\n",
    "print(\n",
    "    f\"The file has {unique_frames} unique frames and {unique_types} unique types: {types_in_video}\"\n",
    ")"
   ],
   "id": "4c489a34b3065774",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "listen_files = train.query('sign == \"listen\"')[\"path\"].values\n",
    "for i, f in enumerate(listen_files):\n",
    "    example_landmark = pd.read_parquet(f\"{BASE_DIR}/{f}\")\n",
    "    unique_frames = example_landmark[\"frame\"].nunique()\n",
    "    unique_types = example_landmark[\"type\"].nunique()\n",
    "    types_in_video = example_landmark[\"type\"].unique()\n",
    "    print(\n",
    "        f\"The file has {unique_frames} unique frames and {unique_types} unique types: {types_in_video}\"\n",
    "    )\n",
    "    if i == 20:\n",
    "        break"
   ],
   "id": "ba7937746f05868a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N_PARQUETS_TO_READ = 100_000  # So we don't have to load all 95k\n",
    "\n",
    "combined_meta = {}\n",
    "for i, d in tqdm(train.iterrows(), total=len(train)):\n",
    "    file_path = d[\"path\"]\n",
    "    example_landmark = pd.read_parquet(f\"{BASE_DIR}/{file_path}\")\n",
    "    # Get the number of landmarks with x,y,z data per type\n",
    "    meta = (\n",
    "        example_landmark.dropna(subset=[\"x\", \"y\", \"z\"])[\"type\"].value_counts().to_dict()\n",
    "    )\n",
    "    meta[\"frames\"] = example_landmark[\"frame\"].nunique()\n",
    "    xyz_meta = (\n",
    "        example_landmark.agg(\n",
    "            {\n",
    "                \"x\": [\"min\", \"max\", \"mean\"],\n",
    "                \"y\": [\"min\", \"max\", \"mean\"],\n",
    "                \"z\": [\"min\", \"max\", \"mean\"],\n",
    "            }\n",
    "        )\n",
    "        .unstack()\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    for key in xyz_meta.keys():\n",
    "        new_key = key[0] + \"_\" + key[1]\n",
    "        meta[new_key] = xyz_meta[key]\n",
    "    combined_meta[file_path] = meta\n",
    "    if i >= N_PARQUETS_TO_READ:\n",
    "        break"
   ],
   "id": "1397bec5e1096cf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_with_meta = train.merge(\n",
    "    pd.DataFrame(combined_meta).T.reset_index().rename(columns={\"index\": \"path\"}),\n",
    "    how=\"left\",\n",
    ")\n",
    "train_with_meta.to_parquet(\"train_with_meta.parquet\")"
   ],
   "id": "4fc190073a00533",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_with_meta[[\"face\", \"pose\", \"left_hand\", \"right_hand\"]].sum().sort_values().plot(\n",
    "    kind=\"barh\", title=\"Sum of Rows by Landmark Type\"\n",
    ")\n",
    "plt.show()"
   ],
   "id": "9a20f46f0a9392a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# checking to see if the number of landmarks for this type is zero\n",
    "(\n",
    "    train_with_meta.query(\"index < 1000\").fillna(0)[\n",
    "        [\"face\", \"pose\", \"left_hand\", \"right_hand\"]\n",
    "    ]\n",
    "    > 0\n",
    ").mean().plot(kind=\"barh\", title=\"Rate of Frame/Keypoints with Data\")"
   ],
   "id": "5b3adf3b84100422",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "example_fn = train_with_meta.dropna().query('sign == \"shhh\"')[\"path\"].values[0]\n",
    "example_landmark = pd.read_parquet(f\"{BASE_DIR}/{example_fn}\")"
   ],
   "id": "68de4fb92ce82147",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "example_landmark.query(\"frame == 25\")[\"type\"].value_counts()",
   "id": "8d3b9bd6c4ab563e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "example_landmark[\"no_xyz\"] = example_landmark[\"x\"].isna()",
   "id": "7aad4ee670a0d708",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "example_landmark.groupby(\"frame\")[\"no_xyz\"].sum().plot(\n",
    "    title=\"missing xyz per frame\", kind=\"bar\"\n",
    ")"
   ],
   "id": "4f8e977371fc4d80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "example_frame = example_landmark.query(\"frame == 17\")\n",
    "px.scatter_3d(example_frame, x=\"x\", y=\"y\", z=\"z\", color=\"type\")"
   ],
   "id": "705919432fd5a3aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "example_landmark[\"y_\"] = example_landmark[\"y\"] * -1\n",
    "example_frame = example_landmark.query(\"frame == 17 and type== 'face'\")\n",
    "px.scatter(example_frame, x=\"x\", y=\"y_\", color=\"type\")"
   ],
   "id": "a3df615960d81b62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install mediapipe --quiet",
   "id": "8b8e2ce375fc9402",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "example_landmark[\"y_\"] = example_landmark[\"y\"] * -1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "for hand in [\"left_hand\", \"right_hand\"]:\n",
    "    example_hand = example_landmark.query(\"frame == 17 and type == @hand\")\n",
    "\n",
    "    ax.scatter(example_hand[\"x\"], example_hand[\"y_\"])\n",
    "\n",
    "    for connection in mp_hands.HAND_CONNECTIONS:\n",
    "        point_a = connection[0]\n",
    "        point_b = connection[1]\n",
    "        x1, y1 = example_hand.query(\"landmark_index == @point_a\")[[\"x\", \"y_\"]].values[0]\n",
    "        x2, y2 = example_hand.query(\"landmark_index == @point_b\")[[\"x\", \"y_\"]].values[0]\n",
    "        plt.plot([x1, x2], [y1, y2], color=\"purple\")\n",
    "ax.set_title(\"Shhh - Hands Data\")\n",
    "plt.show()"
   ],
   "id": "6aaf99941aa91d2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!wget https://i.ytimg.com/vi/mi9f9zOaqM8/hqdefault.jpg --quiet\n",
    "!wget https://previews.123rf.com/images/mimagephotography/mimagephotography1411/mimagephotography141100022/33214722-full-length-portrait-of-a-fashionable-young-man-standing-on-isolated-white-background.jpg --quiet\n"
   ],
   "id": "f549a53f9f7c5b07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = [\n",
    "    \"hqdefault.jpg\",\n",
    "    \"33214722-full-length-portrait-of-a-fashionable-young-man-standing-on-isolated-white-background.jpg\",\n",
    "]\n",
    "BG_COLOR = (192, 192, 192)  # gray\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=2,\n",
    "    enable_segmentation=True,\n",
    "    refine_face_landmarks=True,\n",
    ") as holistic:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        image = cv2.imread(file)\n",
    "        image_height, image_width, _ = image.shape\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            print(\n",
    "                f\"Nose coordinates: (\"\n",
    "                f\"{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, \"\n",
    "                f\"{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_height})\"\n",
    "            )\n",
    "\n",
    "        annotated_image = image.copy()\n",
    "        # Draw segmentation on the image.\n",
    "        # To improve segmentation around boundaries, consider applying a joint\n",
    "        # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
    "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "        bg_image[:] = BG_COLOR\n",
    "        annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "        # Draw pose, left and right hands, and face landmarks on the image.\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated_image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style(),\n",
    "        )\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated_image,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(),\n",
    "        )\n",
    "        cv2.imwrite(\"/tmp/annotated_image\" + str(idx) + \".png\", annotated_image)\n",
    "        # Plot pose world landmarks.\n",
    "#         mp_drawing.plot_landmarks(\n",
    "#             results.pose_world_landmarks, mp_holistic.POSE_CONNECTIONS\n",
    "#         )"
   ],
   "id": "4826460dab7d11a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.imshow(plt.imread(\"/tmp/annotated_image\" + str(0) + \".png\"))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(plt.imread(\"/tmp/annotated_image\" + str(1) + \".png\"))\n",
    "plt.show()"
   ],
   "id": "af3c58265bf09807",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "background_image = np.zeros([720, 720, 3])\n",
    "\n",
    "mp_drawing.draw_landmarks(\n",
    "    background_image,\n",
    "    results.face_landmarks,\n",
    "    mp_holistic.FACEMESH_TESSELATION,\n",
    "    landmark_drawing_spec=None,\n",
    "    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style(),\n",
    ")\n",
    "mp_drawing.draw_landmarks(\n",
    "    background_image,\n",
    "    results.pose_landmarks,\n",
    "    mp_holistic.POSE_CONNECTIONS,\n",
    "    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(),\n",
    ")\n",
    "plt.imshow(background_image)"
   ],
   "id": "f5e901ce9949bafa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "type(results.face_landmarks)\n",
    "\n",
    "from mediapipe.framework.formats import landmark_pb2\n"
   ],
   "id": "56fb897fb73951fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ],
   "id": "17e5344f53973bc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "888739baf925542f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
